#pragma once
#include "compiler.h"
#include "token_strings.h"
#include "memory.h"
#include "tokenizer_t.h"
char* store_string(cunit* cu, char* str, char* str_end);
const char* get_token_type_str(cunit* cu, token_type t);
const char* get_token_str(cunit* cu, token* t);
void tokenizer_open_file(cunit* cu, char* filename);
void tokenizer_close_file(cunit* cu);
void consume_new_token(cunit* cu, token* tok, token* next);
void syntax_error(cunit *cu, token *t, ureg incl_prev, ureg underline_prev, char *str, ...);
void tokenizing_error(cunit* cu, token* t, ureg lines_to_include, char* str, ...);
static inline bool str_eq_keyword(const char* str,const  char* keyword){
    return strcmp(str, keyword) == 0;
}
static inline void inc_token_buff_ptr(cunit* cu, token** p){
    if(*p != &cu->tknzr.token_buffer[TOKEN_BUFFER_SIZE - 1]){
        (*p)++;
    }
    else{
        *p = &cu->tknzr.token_buffer[0];
    }
}
static inline void dec_token_buff_ptr(cunit* cu, token** p){
    if(*p != &cu->tknzr.token_buffer[0]){
        (*p)--;
    }
    else{
        *p = &cu->tknzr.token_buffer[TOKEN_BUFFER_SIZE - 1];
    }
}
static inline token* consume_token(cunit* cu){
    token* s = cu->tknzr.token_start;
    if(cu->tknzr.token_start != cu->tknzr.token_end){
        inc_token_buff_ptr(cu, &cu->tknzr.token_start);
        return s;
    }
    else{
        inc_token_buff_ptr(cu, &cu->tknzr.token_start);
        consume_new_token(cu, s, cu->tknzr.token_start);
        cu->tknzr.token_end = cu->tknzr.token_start;
        return s;
    }
}
static inline token* peek_token(cunit* cu){
     if(cu->tknzr.token_start != cu->tknzr.token_end) {
        return cu->tknzr.token_start;
     }
     else{
         inc_token_buff_ptr(cu, &cu->tknzr.token_end);
         consume_new_token(cu, cu->tknzr.token_start, cu->tknzr.token_end);
         return cu->tknzr.token_start;
     }
}
static inline token* peek_nth_token(cunit* cu, int n){
    n--;
    token* p = cu->tknzr.token_start;
    int i = 0;
    while(i!=n && p != cu->tknzr.token_end){
        inc_token_buff_ptr(cu, &p);
        i++;
    }
    if(i != n){
        do{
            inc_token_buff_ptr(cu, &p);
            consume_new_token(cu, cu->tknzr.token_end, p);
            cu->tknzr.token_end = p;
            i++;
        }while(i != n);
    }
    else{
        if(p == cu->tknzr.token_end){
            inc_token_buff_ptr(cu, &cu->tknzr.token_end);
            consume_new_token(cu, p, cu->tknzr.token_end);
        }
    }
    return p;
}
static inline void clear_lookahead(cunit* cu){
    cu->tknzr.token_start = cu->tknzr.token_end;
}
static inline token* peek_2nd_token(cunit* cu){
    //PERF: maybe optimize this?
    return peek_nth_token(cu, 2);
}
static inline void void_lookahead_token(cunit* cu){
    inc_token_buff_ptr(cu, &cu->tknzr.token_start);
}
static inline void void_lookahead_tokens(cunit *cu, int n){
    for(int i = 0; i< n; i++)inc_token_buff_ptr(cu, &cu->tknzr.token_start);
}
